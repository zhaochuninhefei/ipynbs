{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMwRQ7xj34z+2kbK80aXlKN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhaochuninhefei/ipynbs/blob/master/ChatGLM_6B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ä¸€ã€å‡†å¤‡å·¥ä½œ\n",
        "\n",
        "## 1.1 é€‰æ‹©GPU\n",
        "åœ¨èœå•`ä»£ç æ‰§è¡Œç¨‹åº`ä¸­é€‰æ‹©`æ›´æ”¹è¿è¡Œæ—¶ç±»å‹`,é€‰æ‹©GPTï¼Œå…è´¹çš„T4ã€‚\n",
        "\n",
        "ç„¶åæ£€æŸ¥å½“å‰Nå¡é…ç½®:"
      ],
      "metadata": {
        "id": "e6jDWFk5PCjv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6156BPxJqtp",
        "outputId": "8504c1a2-3c3b-4066-ba0e-e041e118f5c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 29 00:34:57 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¯ä»¥çœ‹åˆ°å…è´¹çš„T4æ˜¾å¡æœ‰15Gæ˜¾å­˜"
      ],
      "metadata": {
        "id": "H_XYcak8j30F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 ä¸‹è½½ChatGLM-6Bé¡¹ç›®\n",
        "é»˜è®¤ä¼šä¸‹è½½åˆ°`/content/ChatGLM-6B`ç›®å½•:"
      ],
      "metadata": {
        "id": "pbELj_2_PaEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/THUDM/ChatGLM-6B.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3fBsFprKKtO",
        "outputId": "f1d7482a-321d-4c14-da19-194eb12a5067"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ChatGLM-6B'...\n",
            "remote: Enumerating objects: 1187, done.\u001b[K\n",
            "remote: Counting objects: 100% (623/623), done.\u001b[K\n",
            "remote: Compressing objects: 100% (119/119), done.\u001b[K\n",
            "remote: Total 1187 (delta 532), reused 545 (delta 504), pack-reused 564\u001b[K\n",
            "Receiving objects: 100% (1187/1187), 9.01 MiB | 26.75 MiB/s, done.\n",
            "Resolving deltas: 100% (701/701), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 å®‰è£…ä¾èµ–åº“\n",
        "æ ¹æ®ChatGLM-6Bé¡¹ç›®ç›®å½•ä¸‹çš„`requirements.txt`æ–‡ä»¶å®‰è£…ç›¸å…³ä¾èµ–åŒ…ã€‚"
      ],
      "metadata": {
        "id": "n5kWUAjPi15g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/ChatGLM-6B/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbgut1sqKQYb",
        "outputId": "60a76f18-402f-4986-c8c9-d877e7967398"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r /content/ChatGLM-6B/requirements.txt (line 1)) (3.20.3)\n",
            "Collecting transformers==4.27.1 (from -r /content/ChatGLM-6B/requirements.txt (line 2))\n",
            "  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cpm_kernels (from -r /content/ChatGLM-6B/requirements.txt (line 3))\n",
            "  Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from -r /content/ChatGLM-6B/requirements.txt (line 4)) (2.0.1+cu118)\n",
            "Collecting gradio (from -r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading gradio-3.32.0-py3-none-any.whl (19.9 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdtex2html (from -r /content/ChatGLM-6B/requirements.txt (line 6))\n",
            "  Downloading mdtex2html-1.2.0-py3-none-any.whl (13 kB)\n",
            "Collecting sentencepiece (from -r /content/ChatGLM-6B/requirements.txt (line 7))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from -r /content/ChatGLM-6B/requirements.txt (line 8))\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r /content/ChatGLM-6B/requirements.txt (line 2)) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.27.1->-r /content/ChatGLM-6B/requirements.txt (line 2))\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r /content/ChatGLM-6B/requirements.txt (line 2)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r /content/ChatGLM-6B/requirements.txt (line 2)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r /content/ChatGLM-6B/requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r /content/ChatGLM-6B/requirements.txt (line 2)) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r /content/ChatGLM-6B/requirements.txt (line 2)) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.1->-r /content/ChatGLM-6B/requirements.txt (line 2))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.27.1->-r /content/ChatGLM-6B/requirements.txt (line 2)) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->-r /content/ChatGLM-6B/requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->-r /content/ChatGLM-6B/requirements.txt (line 4)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->-r /content/ChatGLM-6B/requirements.txt (line 4)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->-r /content/ChatGLM-6B/requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->-r /content/ChatGLM-6B/requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->-r /content/ChatGLM-6B/requirements.txt (line 4)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10->-r /content/ChatGLM-6B/requirements.txt (line 4)) (16.0.5)\n",
            "Collecting aiofiles (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading fastapi-0.95.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.4 (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading gradio_client-0.2.5-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.1/288.1 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading orjson-3.8.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m136.6/136.6 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (1.10.7)\n",
            "Collecting pydub (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (2.14.0)\n",
            "Collecting python-multipart (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from mdtex2html->-r /content/ChatGLM-6B/requirements.txt (line 6)) (3.4.3)\n",
            "Collecting latex2mathml (from mdtex2html->-r /content/ChatGLM-6B/requirements.txt (line 6))\n",
            "  Downloading latex2mathml-3.76.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r /content/ChatGLM-6B/requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.4->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (2023.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.27.1->-r /content/ChatGLM-6B/requirements.txt (line 2)) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->-r /content/ChatGLM-6B/requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5))\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio->-r /content/ChatGLM-6B/requirements.txt (line 5)) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=bffcbb27720d3fa54deccd4ee7e4931fb186747a5b3872dcbe9a2a44e63b9f5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: tokenizers, sentencepiece, pydub, ffmpy, cpm_kernels, websockets, uc-micro-py, semantic-version, python-multipart, orjson, multidict, latex2mathml, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, mdtex2html, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, aiosignal, transformers, httpx, fastapi, aiohttp, gradio-client, gradio, accelerate\n",
            "Successfully installed accelerate-0.19.0 aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 cpm_kernels-1.0.11 fastapi-0.95.2 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.32.0 gradio-client-0.2.5 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 huggingface-hub-0.14.1 latex2mathml-3.76.0 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 mdtex2html-1.2.0 multidict-6.0.4 orjson-3.8.14 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 sentencepiece-0.1.99 starlette-0.27.0 tokenizers-0.13.3 transformers-4.27.1 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# äºŒã€åŠ è½½æ¨¡å‹\n",
        "è¿™é‡Œé€‰æ‹©`chatglm-6b-int4`é‡åŒ–æ¨¡å‹ã€‚\n",
        "> é»˜è®¤çš„`chatglm-6b`(FP16æ— é‡åŒ–æ¨¡å‹)å’Œint8é‡åŒ–æ¨¡å‹éƒ½å› ä¸ºè¿™é‡Œå†…å­˜RAMä¸è¶³(åªæœ‰12.7G)è€Œæ— æ³•æˆåŠŸåŠ è½½æ¨¡å‹ã€‚"
      ],
      "metadata": {
        "id": "jwaWJTfvjYYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b-int4\", trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b-int4\",trust_remote_code=True).half().cuda()\n",
        "# æ— æ³•æˆåŠŸåŠ è½½int8æ¨¡å‹ï¼Œå³ä½¿å»æ‰half()ä¹Ÿä¸è¡Œï¼Œè™½ç„¶åˆ†é…æœ‰12.7Gå†…å­˜ï¼Œä½†å®é™…ä½¿ç”¨æ—¶ä¼¼ä¹ä¸èƒ½è¶…è¿‡6G\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b-int8\", trust_remote_code=True)\n",
        "# model = AutoModel.from_pretrained(\"THUDM/chatglm-6b-int8\",trust_remote_code=True).cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FxsMKT0LnTM",
        "outputId": "6ef2dcb7-0e08-49f9-e6a7-ad4793177792"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
            "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
            "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No compiled kernel found.\n",
            "Compiling kernels : /root/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/02a065cf2797029c036a02cac30f1da1a9bc49a3/quantization_kernels.c\n",
            "Compiling gcc -O3 -fPIC -std=c99 /root/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/02a065cf2797029c036a02cac30f1da1a9bc49a3/quantization_kernels.c -shared -o /root/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/02a065cf2797029c036a02cac30f1da1a9bc49a3/quantization_kernels.so\n",
            "Load kernel : /root/.cache/huggingface/modules/transformers_modules/THUDM/chatglm-6b-int4/02a065cf2797029c036a02cac30f1da1a9bc49a3/quantization_kernels.so\n",
            "Using quantization cache\n",
            "Applying quantization to glm layers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ä¸‰ã€è¿è¡Œæ¨ç†\n",
        "## 3.1 é¦–æ¬¡æ¨ç†\n",
        "é¦–æ¬¡æ¨ç†ä¼šæ…¢ä¸€ç‚¹ã€‚è¿™é‡Œçš„æç¤ºè¯å¾ˆç®€å•ï¼Œå°±æ˜¯`ä½ å¥½`ã€‚"
      ],
      "metadata": {
        "id": "rSpEttOImxJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "model = model.eval()\n",
        "response, history = model.chat(tokenizer, \"ä½ å¥½\", history=[])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlRKX43lM2uE",
        "outputId": "732f93cd-53a1-4a1a-a4c3-c56066d02b97"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.THUDM.chatglm-6b-int4.02a065cf2797029c036a02cac30f1da1a9bc49a3.modeling_chatglm:The dtype of attention mask (torch.int64) is not bool\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n",
            "CPU times: user 8.11 s, sys: 843 ms, total: 8.95 s\n",
            "Wall time: 14.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¯ä»¥çœ‹åˆ°ï¼Œé¦–æ¬¡è¿è¡Œæ¨ç†èŠ±äº†å¤§çº¦15ç§’ã€‚\n",
        "\n",
        "## 3.2 å†æ¬¡æ¨ç†\n",
        "ç„¶åæˆ‘ä»¬å†æ¬¡è¿è¡Œç›¸åŒæç¤ºè¯çš„æ¨ç†ï¼š"
      ],
      "metadata": {
        "id": "4vnR7bAsnG9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response, history = model.chat(tokenizer, \"ä½ å¥½\", history=[])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmu38DL9NOIz",
        "outputId": "d0677265-1fe6-4564-bf16-530787a751a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6Bï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n",
            "CPU times: user 4.89 s, sys: 0 ns, total: 4.89 s\n",
            "Wall time: 4.92 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¿«äº†ä¸å°‘ï¼Œåªè¦å¤§çº¦5ç§’ï¼Œè¿™ä¸ªå…¶å®è¿˜æ˜¯å¾ˆæ…¢ã€‚\n",
        "\n",
        "## 3.3 å…¶ä»–æ¨ç†\n",
        "åœ¨è¿™é‡Œæˆ‘ä»¬å°è¯•ä¸€ä¸‹å…¶ä»–ç¨å¾®å¤æ‚ç‚¹çš„æç¤ºè¯:"
      ],
      "metadata": {
        "id": "PpobeDD8nVYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response, history = model.chat(tokenizer, \"æ¡Œå­ä¸Šæœ‰4ä¸ªè‹¹æœ, å°çº¢åƒäº†1ä¸ª, å°åˆšæ‹¿èµ°äº†2ä¸ª, è¿˜å‰©ä¸‹å‡ ä¸ªè‹¹æœ?\", history=[])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv1Yp_Zpnhp5",
        "outputId": "4570bd44-954b-47fa-88ed-54ac1aa9567b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è¿˜å‰©ä¸‹3ä¸ªè‹¹æœã€‚\n",
            "CPU times: user 1.38 s, sys: 1.13 ms, total: 1.38 s\n",
            "Wall time: 1.5 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™ç§è®¡ç®—æ¨ç†é—®é¢˜ï¼ŒChatGLM-6Bçš„è¡¨ç°ä¸æ˜¯å¾ˆå¥½ã€‚\n",
        "\n",
        "å†å°è¯•ä¸€ä¸ªå¸¸è¯†ç±»é—®é¢˜:"
      ],
      "metadata": {
        "id": "CzUAhzPlnwYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response, history = model.chat(tokenizer, \"ä¸­å›½å››å¤§åè‘—æ˜¯å“ªå››æœ¬ä¹¦?\", history=[])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS20qJB3n502",
        "outputId": "d43462db-f7b3-45a5-c6b7-9cd37f49eb45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ä¸­å›½å››å¤§åè‘—æ˜¯æŒ‡ã€Šçº¢æ¥¼æ¢¦ã€‹ã€ã€Šè¥¿æ¸¸è®°ã€‹ã€ã€Šæ°´æµ’ä¼ ã€‹å’Œã€Šä¸‰å›½æ¼”ä¹‰ã€‹ã€‚è¿™å››æœ¬ä¹¦éƒ½æ˜¯ä¸­å›½æ–‡å­¦å²ä¸Šçš„ç»å…¸ä¹‹ä½œï¼Œè¢«å¹¿æ³›ä¼ è¯µå’Œé˜…è¯»ã€‚\n",
            "CPU times: user 5.37 s, sys: 2.13 ms, total: 5.38 s\n",
            "Wall time: 5.36 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™ä¸ªè¿˜è¡Œï¼Œä½†æœ‰æ—¶ä¹Ÿæœ‰è¯´å¤šé”™å¤šçš„é—®é¢˜ã€‚\n",
        "\n",
        "## 3.4 ä¿¡æ¯æå–\n",
        "å†å°è¯•ä¸€ä¸ªåšä¿¡æ¯æå–çš„ä¾‹å­:"
      ],
      "metadata": {
        "id": "KmUUOnY-oDvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "content=\"\"\"æœ¬äººæ˜¯æ¯•ä¸šäºå—ä¸ƒæŠ€æ ¡ï¼Œæ€§æ ¼å¼€æœ—ï¼Œå¾…äººçœŸè¯šï¼Œå¯¹å¾…å·¥ä½œè®¤çœŸè´Ÿè´£ï¼Œå–„äºæ²Ÿé€šã€åè°ƒæœ‰è¾ƒå¼ºçš„ç»„ç»‡èƒ½åŠ›ä¸å›¢é˜Ÿç²¾ç¥;\n",
        "æ´»æ³¼å¼€æœ—ã€ä¹è§‚ä¸Šè¿›ã€æœ‰çˆ±å¿ƒå¹¶å–„äºæ–½æ•™å¹¶è¡Œ;ä¸Šè¿›å¿ƒå¼ºã€å‹¤äºå­¦ä¹ èƒ½ä¸æ–­æé«˜è‡ªèº«çš„èƒ½åŠ›ä¸ç»¼åˆç´ è´¨ã€‚\n",
        "åœ¨æœªæ¥çš„å·¥ä½œä¸­ï¼Œæˆ‘å°†ä»¥å……æ²›çš„ç²¾åŠ›ï¼Œåˆ»è‹¦é’»ç ”çš„ç²¾ç¥æ¥åŠªåŠ›å·¥ä½œï¼Œç¨³å®šåœ°æé«˜è‡ªå·±çš„å·¥ä½œèƒ½åŠ›ï¼Œä¸å…¬å¸åŒæ­¥å‘å±•ã€‚\n",
        "ç›®å‰æˆ‘å±…ä½åœ¨åˆè‚¥å¸‚äº‘æ·±è·¯234å·å¥‹æ–—å°åŒºï¼Œæˆ‘çš„æ‰‹æœºå·ç æ˜¯: 18012345678ã€‚ä¹Ÿå¯ä»¥ç”¨é‚®ç®±è”ç³»æˆ‘: testtest@test.comã€‚\n",
        "\"\"\"\n",
        "prompt=\"\"\"ä»ä¸Šæ–‡ä¸­ï¼Œæå–\"ä¿¡æ¯\"(keyword:content)ï¼ŒåŒ…æ‹¬:\"æ‰‹æœºå·\"ã€\"é‚®ç®±\"ã€\"æ¯•ä¸šé™¢æ ¡\"ã€\"ä½å€\"ã€\"è‡ªæˆ‘è¯„ä»·\"ç­‰keywordåŠå…¶contentï¼Œè¾“å‡ºjsonæ ¼å¼å†…å®¹ã€‚\n",
        "\"\"\"\n",
        "input ='{}\\n\\n{}'.format(content,prompt)\n",
        "print(input)\n",
        "response, history = model.chat(tokenizer, input, history=[])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6m_B56ONg1a",
        "outputId": "6142fc7f-9f99-4c91-8c01-9bff2f95498e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æœ¬äººæ˜¯æ¯•ä¸šäºå—ä¸ƒæŠ€æ ¡ï¼Œæ€§æ ¼å¼€æœ—ï¼Œå¾…äººçœŸè¯šï¼Œå¯¹å¾…å·¥ä½œè®¤çœŸè´Ÿè´£ï¼Œå–„äºæ²Ÿé€šã€åè°ƒæœ‰è¾ƒå¼ºçš„ç»„ç»‡èƒ½åŠ›ä¸å›¢é˜Ÿç²¾ç¥;\n",
            "æ´»æ³¼å¼€æœ—ã€ä¹è§‚ä¸Šè¿›ã€æœ‰çˆ±å¿ƒå¹¶å–„äºæ–½æ•™å¹¶è¡Œ;ä¸Šè¿›å¿ƒå¼ºã€å‹¤äºå­¦ä¹ èƒ½ä¸æ–­æé«˜è‡ªèº«çš„èƒ½åŠ›ä¸ç»¼åˆç´ è´¨ã€‚\n",
            "åœ¨æœªæ¥çš„å·¥ä½œä¸­ï¼Œæˆ‘å°†ä»¥å……æ²›çš„ç²¾åŠ›ï¼Œåˆ»è‹¦é’»ç ”çš„ç²¾ç¥æ¥åŠªåŠ›å·¥ä½œï¼Œç¨³å®šåœ°æé«˜è‡ªå·±çš„å·¥ä½œèƒ½åŠ›ï¼Œä¸å…¬å¸åŒæ­¥å‘å±•ã€‚\n",
            "ç›®å‰æˆ‘å±…ä½åœ¨åˆè‚¥å¸‚äº‘æ·±è·¯234å·å¥‹æ–—å°åŒºï¼Œæˆ‘çš„æ‰‹æœºå·ç æ˜¯: 18012345678ã€‚ä¹Ÿå¯ä»¥ç”¨é‚®ç®±è”ç³»æˆ‘: testtest@test.comã€‚\n",
            "\n",
            "\n",
            "ä»ä¸Šæ–‡ä¸­ï¼Œæå–\"ä¿¡æ¯\"(keyword:content)ï¼ŒåŒ…æ‹¬:\"æ‰‹æœºå·\"ã€\"é‚®ç®±\"ã€\"æ¯•ä¸šé™¢æ ¡\"ã€\"ä½å€\"ã€\"è‡ªæˆ‘è¯„ä»·\"ç­‰keywordåŠå…¶contentï¼Œè¾“å‡ºjsonæ ¼å¼å†…å®¹ã€‚\n",
            "\n",
            "{  \n",
            " \"æ‰‹æœºå·\": 18012345678,  \n",
            " \"é‚®ç®±\": testtest@test.com,  \n",
            " \"æ¯•ä¸šé™¢æ ¡\": å—ä¸ƒæŠ€æ ¡ï¼Œ  \n",
            " \"ä½å€\": åˆè‚¥å¸‚äº‘æ·±è·¯234å·å¥‹æ–—å°åŒºï¼Œ  \n",
            " \"è‡ªæˆ‘è¯„ä»·\": æ´»æ³¼å¼€æœ—ã€ä¹è§‚ä¸Šè¿›ã€æœ‰çˆ±å¿ƒå¹¶å–„äºæ–½æ•™å¹¶è¡Œï¼›ä¸Šè¿›å¿ƒå¼ºã€å‹¤äºå­¦ä¹ èƒ½ä¸æ–­æé«˜è‡ªèº«çš„èƒ½åŠ›ä¸ç»¼åˆç´ è´¨  \n",
            "}\n",
            "CPU times: user 17.6 s, sys: 2.12 ms, total: 17.6 s\n",
            "Wall time: 17.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™ä¸ªæ•ˆæœè¿˜æ˜¯ä¸é”™çš„ï¼Œè¿™é‡Œå¯ä»¥çœ‹å‡ºæ¥å¾ˆæ˜æ˜¾çš„è¯­å¢ƒå†…å­¦ä¹ èƒ½åŠ›ã€‚\n",
        "\n",
        "## 3.5 ä¿¡æ¯ç»Ÿè®¡\n",
        "### å…ˆæ¥è¯•ä¸€ä¸ªä¿¡æ¯æ”¶é›†ç»Ÿè®¡"
      ],
      "metadata": {
        "id": "pf-HeVlXpr5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "content=\"\"\"æ²³é©¬: å•¦å•¦å•¦å•¦å•¦å•¦å•¦\n",
        "\n",
        "å¼ ä¸‰: æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ\n",
        "\n",
        "æå››: æˆ‘å®¶ä¹Ÿæ–­ç”µäº†\n",
        "\n",
        "ç‹äº”: +1\n",
        "\n",
        "å‚»å¤§ä¸ª: æ²¡æœ‰å•Šï¼Œæˆ‘å®¶æ­£å¸¸çš„å•Š\n",
        "\n",
        "èƒ–å›å­: å•Šè¿™ï¼Œå¥½ç´¯ã€‚\n",
        "\n",
        "å¼ ä¸‰: @ç®¡å®¶ï¼Œä»€ä¹ˆæƒ…å†µï¼Ÿä»€ä¹ˆæ—¶å€™èƒ½æ¥ç”µ? \n",
        "\n",
        "ç‹äº”: åŒé—®\n",
        "\n",
        "å½¼å²¸èŠ±: æˆ‘å®¶ä¹Ÿåœç”µäº†\n",
        "\n",
        "å…”å­: +1\n",
        "\n",
        "æ¯›ç†Š: +1\n",
        "\n",
        "å°é¹°: æ²¡åœç”µçš„é£˜è¿‡ã€‚ã€‚ã€‚\n",
        "\n",
        "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶å°‘å®‰å‹¿èºã€‚\n",
        "\n",
        "æå››: æœ€è¿‘ç»å¸¸åœç”µå•Šï¼Œä¸–ç•Œæœ«æ—¥è¦æ¥äº†ï¼Œå¤§å®¶å‡ºæ¥å—¨å§ï½ï½ï½\n",
        "\n",
        "å±å±: è¿˜å¥½æˆ‘å®¶æ²¡åœã€‚\n",
        "\n",
        "è°å®¶å¤§çˆ·: åˆåœç”µäº†\n",
        "\n",
        "èƒ¡èåœ: +1\n",
        "\n",
        "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶ç¨å®‰å‹¿èºã€‚\n",
        "\n",
        "\"\"\"\n",
        "prompt='é˜…è¯»ä¸Šé¢çš„å¯¹è¯ï¼Œè¯·é—®æœ‰å‡ å®¶åœç”µæˆ–æ–­ç”µäº†?'\n",
        "input ='{}\\n\\n{}'.format(content,prompt)\n",
        "print(input)\n",
        "response, history = model.chat(tokenizer, input, history=[])\n",
        "print()\n",
        "print(\"å›ç­”:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brQq-75O2i8Q",
        "outputId": "584f5bb3-77a3-4209-efc6-c21fff4368da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ²³é©¬: å•¦å•¦å•¦å•¦å•¦å•¦å•¦\n",
            "\n",
            "å¼ ä¸‰: æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ\n",
            "\n",
            "æå››: æˆ‘å®¶ä¹Ÿæ–­ç”µäº†\n",
            "\n",
            "ç‹äº”: +1\n",
            "\n",
            "å‚»å¤§ä¸ª: æ²¡æœ‰å•Šï¼Œæˆ‘å®¶æ­£å¸¸çš„å•Š\n",
            "\n",
            "èƒ–å›å­: å•Šè¿™ï¼Œå¥½ç´¯ã€‚\n",
            "\n",
            "å¼ ä¸‰: @ç®¡å®¶ï¼Œä»€ä¹ˆæƒ…å†µï¼Ÿä»€ä¹ˆæ—¶å€™èƒ½æ¥ç”µ? \n",
            "\n",
            "ç‹äº”: åŒé—®\n",
            "\n",
            "å½¼å²¸èŠ±: æˆ‘å®¶ä¹Ÿåœç”µäº†\n",
            "\n",
            "å…”å­: +1\n",
            "\n",
            "æ¯›ç†Š: +1\n",
            "\n",
            "å°é¹°: æ²¡åœç”µçš„é£˜è¿‡ã€‚ã€‚ã€‚\n",
            "\n",
            "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶å°‘å®‰å‹¿èºã€‚\n",
            "\n",
            "æå››: æœ€è¿‘ç»å¸¸åœç”µå•Šï¼Œä¸–ç•Œæœ«æ—¥è¦æ¥äº†ï¼Œå¤§å®¶å‡ºæ¥å—¨å§ï½ï½ï½\n",
            "\n",
            "å±å±: è¿˜å¥½æˆ‘å®¶æ²¡åœã€‚\n",
            "\n",
            "è°å®¶å¤§çˆ·: åˆåœç”µäº†\n",
            "\n",
            "èƒ¡èåœ: +1\n",
            "\n",
            "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶ç¨å®‰å‹¿èºã€‚\n",
            "\n",
            "\n",
            "\n",
            "é˜…è¯»ä¸Šé¢çš„å¯¹è¯ï¼Œè¯·é—®æœ‰å‡ å®¶åœç”µæˆ–æ–­ç”µäº†?\n",
            "\n",
            "å›ç­”:\n",
            "åœ¨è¿™æ®µå¯¹è¯ä¸­ï¼Œæœ‰5ä¸ªäººæåˆ°äº†ä»–ä»¬å®¶é‡Œæœ€è¿‘åœç”µäº†ã€‚\n",
            "CPU times: user 2.93 s, sys: 11.1 ms, total: 2.95 s\n",
            "Wall time: 4.01 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¾ˆé—æ†¾ï¼Œç»Ÿè®¡ç»“æœä¸æ­£ç¡®ï¼Œå®é™…ä¸Šåº”è¯¥æ˜¯8å®¶åœç”µã€‚å¤šè¯•å‡ æ¬¡ä¼šå‘ç°ï¼Œè¿™ç§ç»Ÿè®¡å¯¹chatGLMæ¥è¯´è¿˜æ˜¯å¤ªéš¾äº†ï¼Œå¶å°”èƒ½è’™å¯¹ä¸€æ¬¡ã€‚\n",
        "\n",
        "### å†è¯•ä¸€ä¸‹åªæœ‰ä¸€å®¶åœç”µçš„åœºæ™¯"
      ],
      "metadata": {
        "id": "WWgQiYEx3GTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "content=\"\"\"æ²³é©¬: å•¦å•¦å•¦å•¦å•¦å•¦å•¦\n",
        "\n",
        "å¼ ä¸‰: æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ\n",
        "\n",
        "æå››: æˆ‘å®¶æ­£å¸¸\n",
        "\n",
        "ç‹äº”: æ­£å¸¸+1\n",
        "\n",
        "å‚»å¤§ä¸ª: æ²¡æœ‰å•Šï¼Œæˆ‘å®¶æ­£å¸¸çš„å•Š\n",
        "\n",
        "èƒ–å›å­: å•Šè¿™ï¼Œå¥½ç´¯ã€‚\n",
        "\n",
        "å¼ ä¸‰: @ç®¡å®¶ï¼Œä»€ä¹ˆæƒ…å†µï¼Ÿä»€ä¹ˆæ—¶å€™èƒ½æ¥ç”µ? \n",
        "\n",
        "ç‹äº”: æ­£å¸¸+1\n",
        "\n",
        "å½¼å²¸èŠ±: æˆ‘å®¶æ­£å¸¸\n",
        "\n",
        "å…”å­: æ­£å¸¸+1\n",
        "\n",
        "æ¯›ç†Š: æ­£å¸¸+1\n",
        "\n",
        "å°é¹°: æ²¡åœç”µçš„é£˜è¿‡ã€‚ã€‚ã€‚\n",
        "\n",
        "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶å°‘å®‰å‹¿èºã€‚\n",
        "\n",
        "æå››: ä¸–ç•Œæœ«æ—¥è¦æ¥äº†ï¼Œå¤§å®¶å‡ºæ¥å—¨å§ï½ï½ï½\n",
        "\n",
        "å±å±: è¿˜å¥½æˆ‘å®¶æ²¡åœã€‚\n",
        "\n",
        "è°å®¶å¤§çˆ·: æˆ‘å®¶æ²¡åœç”µ\n",
        "\n",
        "èƒ¡èåœ: æ²¡åœ+1\n",
        "\n",
        "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶ç¨å®‰å‹¿èºã€‚\n",
        "\n",
        "\"\"\"\n",
        "prompt='é˜…è¯»ä¸Šé¢çš„å¯¹è¯ï¼Œè¯·é—®æœ‰å‡ å®¶åœç”µæˆ–æ–­ç”µäº†?'\n",
        "input ='{}\\n\\n{}'.format(content,prompt)\n",
        "print(input)\n",
        "response, history = model.chat(tokenizer, input, history=[])\n",
        "print()\n",
        "print(\"å›ç­”:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpX8Peef-Ekj",
        "outputId": "7c84b146-fcfb-4ba3-ed5c-cbf238cd6f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "æ²³é©¬: å•¦å•¦å•¦å•¦å•¦å•¦å•¦\n",
            "\n",
            "å¼ ä¸‰: æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ\n",
            "\n",
            "æå››: æˆ‘å®¶æ­£å¸¸\n",
            "\n",
            "ç‹äº”: æ­£å¸¸+1\n",
            "\n",
            "å‚»å¤§ä¸ª: æ²¡æœ‰å•Šï¼Œæˆ‘å®¶æ­£å¸¸çš„å•Š\n",
            "\n",
            "èƒ–å›å­: å•Šè¿™ï¼Œå¥½ç´¯ã€‚\n",
            "\n",
            "å¼ ä¸‰: @ç®¡å®¶ï¼Œä»€ä¹ˆæƒ…å†µï¼Ÿä»€ä¹ˆæ—¶å€™èƒ½æ¥ç”µ? \n",
            "\n",
            "ç‹äº”: æ­£å¸¸+1\n",
            "\n",
            "å½¼å²¸èŠ±: æˆ‘å®¶æ­£å¸¸\n",
            "\n",
            "å…”å­: æ­£å¸¸+1\n",
            "\n",
            "æ¯›ç†Š: æ­£å¸¸+1\n",
            "\n",
            "å°é¹°: æ²¡åœç”µçš„é£˜è¿‡ã€‚ã€‚ã€‚\n",
            "\n",
            "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶å°‘å®‰å‹¿èºã€‚\n",
            "\n",
            "æå››: ä¸–ç•Œæœ«æ—¥è¦æ¥äº†ï¼Œå¤§å®¶å‡ºæ¥å—¨å§ï½ï½ï½\n",
            "\n",
            "å±å±: è¿˜å¥½æˆ‘å®¶æ²¡åœã€‚\n",
            "\n",
            "è°å®¶å¤§çˆ·: æˆ‘å®¶æ²¡åœç”µ\n",
            "\n",
            "èƒ¡èåœ: æ²¡åœ+1\n",
            "\n",
            "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶ç¨å®‰å‹¿èºã€‚\n",
            "\n",
            "\n",
            "\n",
            "é˜…è¯»ä¸Šé¢çš„å¯¹è¯ï¼Œè¯·é—®æœ‰å‡ å®¶åœç”µæˆ–æ–­ç”µäº†?\n",
            "\n",
            "å›ç­”:\n",
            "æ ¹æ®å¯¹è¯ä¸­çš„ä¿¡æ¯ï¼Œæœ‰å‡ å®¶åœç”µæˆ–æ–­ç”µäº†ï¼š\n",
            "\n",
            "- å¼ ä¸‰ï¼š çªç„¶æ–­ç”µäº†ï¼Ÿ\n",
            "- æå››ï¼š æˆ‘å®¶æ­£å¸¸\n",
            "- ç‹äº”ï¼š æ­£å¸¸+1\n",
            "- å‚»å¤§ä¸ªï¼š æ²¡æœ‰å•Šï¼Œæˆ‘å®¶æ­£å¸¸çš„å•Š\n",
            "- èƒ–å›å­ï¼š å•Šè¿™ï¼Œå¥½ç´¯\n",
            "- å½¼å²¸èŠ±ï¼š æˆ‘å®¶æ­£å¸¸\n",
            "- å…”å­ï¼š æ­£å¸¸+1\n",
            "- æ¯›ç†Šï¼š æ­£å¸¸+1\n",
            "- å°é¹°ï¼š æ²¡åœç”µçš„é£˜è¿‡\n",
            "- ç®¡å®¶ï¼š æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶å°‘å®‰å‹¿èº\n",
            "- æå››ï¼š ä¸–ç•Œæœ«æ—¥è¦æ¥äº†ï¼Œå¤§å®¶å‡ºæ¥å—¨å§ï½ï½ï½\n",
            "- å±å±ï¼š è¿˜å¥½æˆ‘å®¶æ²¡åœ\n",
            "- è°å®¶å¤§çˆ·ï¼š æˆ‘å®¶æ²¡åœç”µ\n",
            "- èƒ¡èåœï¼š æ²¡åœ+1\n",
            "\n",
            "å› æ­¤ï¼Œæœ‰4å®¶åœç”µæˆ–æ–­ç”µäº†ã€‚\n",
            "CPU times: user 33.6 s, sys: 88.8 ms, total: 33.7 s\n",
            "Wall time: 33.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¿™ä¸ªå°±æ›´éš¾äº†ï¼Œç»“æœå®åœ¨ç¦»è°±ã€‚\n",
        "\n",
        "### å¦‚æœæç¤ºè¯åŠ å…¥ç¤ºä¾‹ï¼Œå†æ¥çœ‹ä¸€ä¸‹ç»“æœ"
      ],
      "metadata": {
        "id": "g13S7wZf_Z_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "content=\"\"\"è¯·ç»Ÿè®¡ä¸€æ®µå¯¹è¯ä¸­åœç”µçš„æˆ·æ•°æœ‰å¤šå°‘ã€‚\n",
        "ä¾‹1:\n",
        "```\n",
        "å¼ ä¸‰: æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ\n",
        "æå››: æˆ‘å®¶ä¹Ÿæ–­ç”µäº†\n",
        "ç‹äº”: +1\n",
        "å‚»å¤§ä¸ª: æ²¡æœ‰å•Šï¼Œæˆ‘å®¶æ­£å¸¸çš„å•Š\n",
        "èƒ–å›å­: å•Šè¿™ï¼Œå¥½ç´¯ã€‚\n",
        "```\n",
        "åº”è¯¥ç»Ÿè®¡å‡ºåœç”µæˆ·æ•°:3ã€‚\n",
        "\n",
        "ä¾‹2ï¼š\n",
        "```\n",
        "å¼ ä¸‰: æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ\n",
        "æå››: æˆ‘å®¶æ²¡æ–­ç”µå•Š\n",
        "ç‹äº”: æ²¡æ–­ç”µ+1\n",
        "å‚»å¤§ä¸ª: æˆ‘å®¶ä¹Ÿæ­£å¸¸çš„å•Š\n",
        "èƒ–å›å­: æ­£å¸¸+1\n",
        "```\n",
        "åº”è¯¥ç»Ÿè®¡å‡ºåœç”µæˆ·æ•°:1ã€‚\n",
        "\n",
        "è¯·æŒ‰ç…§åŒæ ·çš„è§„åˆ™ç»Ÿè®¡ä¸‹é¢è¿™æ®µå¯¹è¯çš„åœç”µæˆ·æ•°:\n",
        "```\n",
        "æ²³é©¬: å•¦å•¦å•¦å•¦å•¦å•¦å•¦\n",
        "å°æ˜: æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ\n",
        "å°èŠ³: æˆ‘å®¶ä¹Ÿæ–­ç”µäº†\n",
        "å°å: +1\n",
        "é˜¿è¾¾: æ²¡æœ‰å•Šï¼Œæˆ‘å®¶æ­£å¸¸çš„å•Š\n",
        "å›è«ç¬‘: å•Šè¿™ï¼Œå¥½ç´¯ã€‚\n",
        "å°æ˜: @ç®¡å®¶ï¼Œä»€ä¹ˆæƒ…å†µï¼Ÿä»€ä¹ˆæ—¶å€™èƒ½æ¥ç”µ? \n",
        "å°å: åŒé—®\n",
        "å½¼å²¸èŠ±: æˆ‘å®¶ä¹Ÿåœç”µäº†\n",
        "é¸½å­: +1\n",
        "å¤§ç†Š: +1\n",
        "è€é¹°: æ²¡åœç”µçš„é£˜è¿‡ã€‚ã€‚ã€‚\n",
        "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶å°‘å®‰å‹¿èºã€‚\n",
        "å°èŠ³: æœ€è¿‘ç»å¸¸åœç”µå•Šï¼Œä¸–ç•Œæœ«æ—¥è¦æ¥äº†ï¼Œå¤§å®¶å‡ºæ¥å—¨å§ï½ï½ï½\n",
        "å±å±: è¿˜å¥½æˆ‘å®¶æ²¡åœã€‚\n",
        "è°å®¶å¤§çˆ·: æ²¡åœç”µ+1\n",
        "èƒ¡èåœ: æ²¡åœç”µ+1\n",
        "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶ç¨å®‰å‹¿èºã€‚\n",
        "```\n",
        "\"\"\"\n",
        "print(content)\n",
        "response, history = model.chat(tokenizer, content, history=[])\n",
        "print()\n",
        "print(\"å›ç­”:\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOUlfnu7HECn",
        "outputId": "095d4c4b-d15d-434c-a690-18f5e4298ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "è¯·ç»Ÿè®¡ä¸€æ®µå¯¹è¯ä¸­åœç”µçš„æˆ·æ•°æœ‰å¤šå°‘ã€‚\n",
            "ä¾‹1:\n",
            "```\n",
            "å¼ ä¸‰: æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ\n",
            "æå››: æˆ‘å®¶ä¹Ÿæ–­ç”µäº†\n",
            "ç‹äº”: +1\n",
            "å‚»å¤§ä¸ª: æ²¡æœ‰å•Šï¼Œæˆ‘å®¶æ­£å¸¸çš„å•Š\n",
            "èƒ–å›å­: å•Šè¿™ï¼Œå¥½ç´¯ã€‚\n",
            "```\n",
            "åº”è¯¥ç»Ÿè®¡å‡ºåœç”µæˆ·æ•°:3ã€‚\n",
            "\n",
            "ä¾‹2ï¼š\n",
            "```\n",
            "å¼ ä¸‰: æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ\n",
            "æå››: æˆ‘å®¶æ²¡æ–­ç”µå•Š\n",
            "ç‹äº”: æ²¡æ–­ç”µ+1\n",
            "å‚»å¤§ä¸ª: æˆ‘å®¶ä¹Ÿæ­£å¸¸çš„å•Š\n",
            "èƒ–å›å­: æ­£å¸¸+1\n",
            "```\n",
            "åº”è¯¥ç»Ÿè®¡å‡ºåœç”µæˆ·æ•°:1ã€‚\n",
            "\n",
            "è¯·æŒ‰ç…§åŒæ ·çš„è§„åˆ™ç»Ÿè®¡ä¸‹é¢è¿™æ®µå¯¹è¯çš„åœç”µæˆ·æ•°:\n",
            "```\n",
            "æ²³é©¬: å•¦å•¦å•¦å•¦å•¦å•¦å•¦\n",
            "å°æ˜: æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ\n",
            "å°èŠ³: æˆ‘å®¶ä¹Ÿæ–­ç”µäº†\n",
            "å°å: +1\n",
            "é˜¿è¾¾: æ²¡æœ‰å•Šï¼Œæˆ‘å®¶æ­£å¸¸çš„å•Š\n",
            "å›è«ç¬‘: å•Šè¿™ï¼Œå¥½ç´¯ã€‚\n",
            "å°æ˜: @ç®¡å®¶ï¼Œä»€ä¹ˆæƒ…å†µï¼Ÿä»€ä¹ˆæ—¶å€™èƒ½æ¥ç”µ? \n",
            "å°å: åŒé—®\n",
            "å½¼å²¸èŠ±: æˆ‘å®¶ä¹Ÿåœç”µäº†\n",
            "é¸½å­: +1\n",
            "å¤§ç†Š: +1\n",
            "è€é¹°: æ²¡åœç”µçš„é£˜è¿‡ã€‚ã€‚ã€‚\n",
            "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶å°‘å®‰å‹¿èºã€‚\n",
            "å°èŠ³: æœ€è¿‘ç»å¸¸åœç”µå•Šï¼Œä¸–ç•Œæœ«æ—¥è¦æ¥äº†ï¼Œå¤§å®¶å‡ºæ¥å—¨å§ï½ï½ï½\n",
            "å±å±: è¿˜å¥½æˆ‘å®¶æ²¡åœã€‚\n",
            "è°å®¶å¤§çˆ·: æ²¡åœç”µ+1\n",
            "èƒ¡èåœ: æ²¡åœç”µ+1\n",
            "ç®¡å®¶: æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶ç¨å®‰å‹¿èºã€‚\n",
            "```\n",
            "\n",
            "\n",
            "å›ç­”:\n",
            "æ ¹æ®ä¸Šé¢çš„ä¾‹å­ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä»¥ä¸‹ç»Ÿè®¡ç»“æœï¼š\n",
            "\n",
            "- æ²³é©¬ï¼š å•¦å•¦å•¦å•¦å•¦å•¦å•¦  \n",
            "- å°æ˜ï¼š æ€ä¹ˆå›äº‹ï¼Ÿçªç„¶æ–­ç”µäº†ï¼Ÿ  \n",
            "- å°èŠ³ï¼š æˆ‘å®¶ä¹Ÿæ–­ç”µäº†  \n",
            "- å°åï¼š +1  \n",
            "- é˜¿è¾¾ï¼š æ²¡æœ‰å•Šï¼Œæˆ‘å®¶æ­£å¸¸çš„å•Š  \n",
            "- å›è«ç¬‘ï¼š å•Šè¿™ï¼Œå¥½ç´¯  \n",
            "- å°æ˜ï¼š @ç®¡å®¶ï¼Œä»€ä¹ˆæƒ…å†µï¼Ÿä»€ä¹ˆæ—¶å€™èƒ½æ¥ç”µï¼Ÿ  \n",
            "- å°åï¼š åŒé—®  \n",
            "- å½¼å²¸èŠ±ï¼š æˆ‘å®¶ä¹Ÿåœç”µäº†  \n",
            "- é¸½å­ï¼š +1  \n",
            "- å¤§ç†Šï¼š +1  \n",
            "- è€é¹°ï¼š æ²¡åœç”µçš„é£˜è¿‡ã€‚ã€‚ã€‚  \n",
            "- ç®¡å®¶ï¼š æ­£åœ¨è”ç³»ä¾›ç”µå±€ï¼Œè¯·å¤§å®¶å°‘å®‰å‹¿èºã€‚  \n",
            "- å°èŠ³ï¼š æœ€è¿‘ç»å¸¸åœç”µå•Šï¼Œä¸–ç•Œæœ«æ—¥è¦æ¥äº†ï¼Œå¤§å®¶å‡ºæ¥å—¨å§ï½ï½ï½  \n",
            "- å±å±ï¼š è¿˜å¥½æˆ‘å®¶æ²¡åœã€‚  \n",
            "- è°å®¶å¤§çˆ·ï¼š æ²¡åœç”µ+1  \n",
            "- èƒ¡èåœï¼š æ²¡åœç”µ+1  \n",
            "\n",
            "å› æ­¤ï¼Œè¿™æ®µå¯¹è¯ä¸­çš„åœç”µæˆ·æ•°ä¸ºï¼š3ã€‚\n",
            "CPU times: user 44.6 s, sys: 73.4 ms, total: 44.7 s\n",
            "Wall time: 44.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœ€åè¿™ä¸ªä¾ç„¶ä¸é è°±ã€‚\n",
        "ä½†åŒæ ·çš„æç¤ºè¯ï¼Œæœ€åè¿™ç§å¸¦ç¤ºä¾‹çš„ï¼Œåœ¨new bingé‚£é‡Œèƒ½å¾—åˆ°æ­£ç¡®ç»“æœï¼Œå¹¶ä¸”new bingä¼šç»™å‡ºç»Ÿè®¡è¿‡ç¨‹ã€‚"
      ],
      "metadata": {
        "id": "l-JGjNnoSFza"
      }
    }
  ]
}